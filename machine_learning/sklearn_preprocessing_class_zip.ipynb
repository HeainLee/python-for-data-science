{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pandas.core.common import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수 스케일링 방법(!!)\n",
    "\n",
    "참고: https://sebastianraschka.com/faq/docs/scale-training-test.html\n",
    "1. 학습데이터와 실험데이터 구분\n",
    "2. 학습데이터의 특정 변수 스케일링 (fit)\n",
    "3. 학습데이터의 특정 변수에 스케일링 적용(transform)\n",
    "4. (스케일링된 학습데이터로 모델 학습) - 모델은 스케일링된 데이터를 통해 학습됨 \n",
    "5. 실험데이터의 특정 변수(학습데이터에서 스케일링 적용한 변수와 동일) 스케일링 적용(transform, fit하지 않음)\n",
    "6. (스케일링된 실험데이터로 모델 적용)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir=os.getcwd()\n",
    "data_dir = os.path.join(os.path.join(current_dir, 'example'),'bike_demand')\n",
    "data_dir\n",
    "bike = pd.read_csv(data_dir+'\\\\bike_train.csv')\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sd_scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "ma_scaler = MaxAbsScaler(copy=True)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rb_scaler = RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True, with_scaling=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer(params):\n",
    "    module_ = __import__(params['LIBRARY_NAME'])\n",
    "    class_ = getattr(module_, params['LIBRARY_OBJECT_NAME'])\n",
    "    transformer_ = getattr(class_, params['LIBRARY_FUNCTION_NAME'])\n",
    "    transformer  = transformer_()\n",
    "    return transformer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'LIBRARY_FUNCTION_NAME': 'StandardScaler',\n",
       "  'LIBRARY_NAME': 'sklearn',\n",
       "  'LIBRARY_OBJECT_NAME': 'preprocessing',\n",
       "  'pk': 1},\n",
       " '2': {'LIBRARY_FUNCTION_NAME': 'MinMaxScaler',\n",
       "  'LIBRARY_NAME': 'sklearn',\n",
       "  'LIBRARY_OBJECT_NAME': 'preprocessing',\n",
       "  'pk': 2},\n",
       " '3': {'LIBRARY_FUNCTION_NAME': 'OneHotEncoder',\n",
       "  'LIBRARY_NAME': 'sklearn',\n",
       "  'LIBRARY_OBJECT_NAME': 'preprocessing',\n",
       "  'pk': 3}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfunc_01 = dict(pk=1, LIBRARY_NAME='sklearn', LIBRARY_OBJECT_NAME='preprocessing', LIBRARY_FUNCTION_NAME='StandardScaler')\n",
    "pfunc_02 = dict(pk=2, LIBRARY_NAME='sklearn', LIBRARY_OBJECT_NAME='preprocessing', LIBRARY_FUNCTION_NAME='MinMaxScaler')\n",
    "pfunc_03 = dict(pk=3, LIBRARY_NAME='sklearn', LIBRARY_OBJECT_NAME='preprocessing', LIBRARY_FUNCTION_NAME='OneHotEncoder')\n",
    "pfunc = {}\n",
    "pfunc['1'] = pfunc_01\n",
    "pfunc['2'] = pfunc_02\n",
    "pfunc['3'] = pfunc_03\n",
    "pfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변수선택:atemp\n",
      "변환기선택(처리방식):minmax\n",
      "선택된 변수 [atemp] 를 [minmax]를 이용해서 변환합니다.\n"
     ]
    }
   ],
   "source": [
    "COLUMN = input('변수선택:')\n",
    "TRANSFROMER = input('변환기선택(처리방식):')\n",
    "print('선택된 변수 [{}] 를 [{}] 를 이용해서 변환합니다.'.format(COLUMN, TRANSFROMER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = bike.copy()\n",
    "COLUMN = 'atemp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.395],\n",
       "       [13.635],\n",
       "       [13.635],\n",
       "       [14.395],\n",
       "       [14.395]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_data = DATA[COLUMN][:5].values.reshape(-1,1)\n",
    "unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'req_01': {'condition': '', 'field_name': 'atemp', 'pfunc_pk': 1},\n",
      " 'req_02': {'condition': {'feature_range': (-1, 1)},\n",
      "            'field_name': 'humidity',\n",
      "            'pfunc_pk': 2}}\n"
     ]
    }
   ],
   "source": [
    "request = {}\n",
    "request['req_01'] = dict(pfunc_pk=1, field_name='atemp', condition='')\n",
    "request['req_02'] = dict(pfunc_pk=2, field_name='humidity', condition={'feature_range':(-1,1)})\n",
    "pprint(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get  user  request   field=>  atemp\n",
      "set user request condition=>  StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "==============done==============\n",
      "\n",
      "get  user  request   field=>  humidity\n",
      "set user request condition=>  MinMaxScaler(copy=True, feature_range=(-1, 1))\n",
      "==============done==============\n",
      "\n",
      "get  user  request   field=>  temp\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-389-57db124d138a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print('get   default  transformer=> ', transformer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get  user  request   field=> '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_request_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'field_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mget_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_request_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'condition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_condition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'set user request condition=> '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'condition'"
     ]
    }
   ],
   "source": [
    "DF = pd.DataFrame()\n",
    "NUM = 5 \n",
    "for user_request in request:\n",
    "    #print(request[user_request]) #{'pfunc_pk': 1, 'field_name': 'atemp', 'condition': ''}\n",
    "    get_request_dict = request[user_request]\n",
    "    get_pk = get_request_dict['pfunc_pk']\n",
    "    get_pfunc = pfunc[str(get_pk)]\n",
    "    #print(get_pfunc) #{'pk': 1, 'LIBRARY_NAME': 'sklearn', 'LIBRARY_OBJECT_NAME': 'preprocessing', 'LIBRARY_FUNCTION_NAME': 'StandardScaler'}\n",
    "    transformer = get_transformer(get_pfunc)\n",
    "    get_field = DATA[get_request_dict['field_name']][:NUM]\n",
    "    #print('get   default  transformer=> ', transformer)\n",
    "    print('get  user  request   field=> ', get_request_dict['field_name'])\n",
    "    get_condition = get_request_dict['condition']\n",
    "    transformer = change_params(transformer, get_condition)\n",
    "    print('set user request condition=> ', transformer)\n",
    "    get_field=get_field.astype(float)\n",
    "    try:\n",
    "        transformer.fit(get_field)\n",
    "        changed_f1 = transformer.fit_transform(get_field)\n",
    "    except:\n",
    "        transformer.fit(get_field.values.reshape(-1,1))\n",
    "        changed_f1 = transformer.fit_transform(get_field.values.reshape(-1,1))\n",
    "    #print(list(flatten(changed_f1)))#NUM])\n",
    "    #changed_data[get_request_dict['field_name']]= list(flatten(changed_f1))  #:NUM]\n",
    "    result = changed_f1\n",
    "    to_df = pd.DataFrame(result, columns=[get_request_dict['field_name']])\n",
    "    DF = pd.concat([DF, to_df], axis=1)\n",
    "    print('==============done==============\\n')\n",
    "    \n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'atemp': 0.816496580927727, 'humidity': 1.0},\n",
       " {'atemp': -1.224744871391588, 'humidity': 0.6666666666666643},\n",
       " {'atemp': -1.224744871391588, 'humidity': 0.6666666666666643},\n",
       " {'atemp': 0.816496580927727, 'humidity': -1.0},\n",
       " {'atemp': 0.816496580927727, 'humidity': -1.0}]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {}\n",
    "request['req_01'] = dict(pfunc_pk=1, field_name='atemp', condition='')\n",
    "request['req_02'] = dict(pfunc_pk=2, field_name='humidity', condition={'feature_range':(-1,1)})\n",
    "request['req_03'] = dict(pfunc_pk=1, field_name='temp')\n",
    "request['req_04'] = dict(pfunc_pk=3, field_name='weather', condition={'categories':'auto', 'sparse':False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## string to dictionary (08.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature_range:(-1,1)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_req = '{\"PREPROCESS_FUNCTIONS_SEQUENCE_PK\":1, \"field_name\":\"temp\", \"condition\":\"feature_range:(-1,1)\"}' #, sth:30\n",
    "full_dict = json.loads(full_req)\n",
    "con = full_dict['condition']\n",
    "con = con.lower()\n",
    "con "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_range': '(-1,1)'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inspect_condition(params_str):\n",
    "    condition_list = params_str.split(', ')\n",
    "    params_dict = {}\n",
    "    for request_conidtion in condition_list:\n",
    "        key_, values_ = request_conidtion.split(':')[0], request_conidtion.split(':')[1]\n",
    "        params_dict[key_] = values_\n",
    "    return params_dict\n",
    "\n",
    "get_params_dict = inspect_condition(con)\n",
    "get_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오리지널 {'copy': True, 'feature_range': (0, 1)}\n",
      "파라미터 변경 후 {'copy': True, 'feature_range': (-1, 1)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.38986464, -0.55102041],\n",
       "       [-0.42387292, -0.59183673],\n",
       "       [-0.42387292, -0.59183673],\n",
       "       ...,\n",
       "       [-0.32207182, -0.34693878],\n",
       "       [-0.254279  , -0.34693878],\n",
       "       [-0.28828728, -0.3877551 ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from distutils import util # to handle str to bool conversion\n",
    "\n",
    "\n",
    "tf = MinMaxScaler()\n",
    "print('오리지널', tf.get_params())\n",
    "x = {}\n",
    "for param_key_, param_values_ in get_params_dict.items():\n",
    "    if param_values_ == 'true' or param_values_ == 'false':\n",
    "        param_values_ = bool(util.strtobool(param_values_))\n",
    "        #param_values_ = (False, True)[param_values_ == \"True\"]\n",
    "    elif param_values_.startswith('('):\n",
    "        param_values_ = literal_eval(param_values_)\n",
    "    x[param_key_] = param_values_\n",
    "\n",
    "tf = tf.set_params(**x)\n",
    "print('파라미터 변경 후', tf.get_params())\n",
    "tf.fit_transform(DATA[['atemp', 'temp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.5510204081632654,\n",
       " -0.5918367346938775,\n",
       " -0.5918367346938775,\n",
       " -0.5510204081632654,\n",
       " -0.5510204081632654]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_list = [-0.5510204081632654, -0.5918367346938775, -0.5918367346938775, -0.5510204081632654, -0.5510204081632654]\n",
    "r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.5510', '-0.5918', '-0.5918', '-0.5510', '-0.5510']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: format(x, '.4f'), r_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x*2, [1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"PREPROCESS_FUNCTIONS_SEQUENCE_PK\":1, \"field_name\":\"temp\", \"condition\":\"copy:False, feature_range:(0,1), sth:30\"}\n",
      "b'{\"PREPROCESS_FUNCTIONS_SEQUENCE_PK\":1, \"field_name\":\"temp\", \"condition\":\"copy:False, feature_range:(0,1), sth:30\"}'\n",
      "full_dict['condition'] copy:False, feature_range:(0,1), sth:30\n",
      "<class 'str'>\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "full_req = '{\"PREPROCESS_FUNCTIONS_SEQUENCE_PK\":1, \"field_name\":\"temp\", \"condition\":\"copy:False, feature_range:(0,1), sth:30\"}'\n",
    "#, \"condition\":\"{\"copy\":\"False\"}\"'\n",
    "print(full_req)\n",
    "full_req = full_req.encode(\"utf-8\")\n",
    "print(full_req)\n",
    "full_dict = json.loads(full_req)\n",
    "type(full_dict)\n",
    "print(\"full_dict['condition']\",full_dict['condition'])\n",
    "con = full_dict['condition']\n",
    "print(type(con))\n",
    "\n",
    "\n",
    "tf = MinMaxScaler()\n",
    "print(tf)\n",
    "tf_scaled = change_params(tf, con)\n",
    "print(tf_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "{'copy': False}\n",
      "MinMaxScaler(copy=False, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "tf = MinMaxScaler()\n",
    "print(tf)\n",
    "full_dict = dict(copy=False)\n",
    "print(full_dict)\n",
    "tf_scaled = change_params(tf, full_dict)\n",
    "print(tf_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 76 (char 75)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-731-6ab0020a8086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfull_req\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{\"PREPROCESS_FUNCTIONS_SEQUENCE_PK\":1, \"field_name\":\"temp\", \"condition\":\"{\"copy\":False}\"}'\u001b[0m \u001b[1;31m#\"{feature_range:(-1, 1)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfull_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_req\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"condition\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'condition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"condition\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 76 (char 75)"
     ]
    }
   ],
   "source": [
    "full_req = '{\"PREPROCESS_FUNCTIONS_SEQUENCE_PK\":1, \"field_name\":\"temp\", \"condition\":\"{\"copy\":False}\"}' #\"{feature_range:(-1, 1)}\"\n",
    "full_dict = json.loads(full_req)\n",
    "print(type(full_dict[\"condition\"]))\n",
    "print(full_dict['condition'])\n",
    "con = full_dict[\"condition\"]\n",
    "print(con)\n",
    "n, v = con.strip('{}').split(\":\")\n",
    "con_dict = {}\n",
    "con_dict[n] = v\n",
    "print('con_dict', con_dict)\n",
    "#a_dict = dict([con.strip('{}').split(\":\"),])\n",
    "#print(a_dict)\n",
    "#a_dict['feature_range']\n",
    "\n",
    "tf = MinMaxScaler()\n",
    "print(tf)\n",
    "for k, v in param.items():\n",
    "    setattr(tf, k, v)\n",
    "tf.fit_transform(DATA[['atemp', 'temp']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = '{\"feature_range\": \"(-1, 1)\", \"copy\":\"False\"}'\n",
    "con = json.loads(con)\n",
    "tf = MinMaxScaler()\n",
    "params = {}\n",
    "print(tf)\n",
    "for name, values in con.items():\n",
    "    params[name] = values\n",
    "    \n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38986464, -0.55102041],\n",
       "       [-0.42387292, -0.59183673],\n",
       "       [-0.42387292, -0.59183673],\n",
       "       ...,\n",
       "       [-0.32207182, -0.34693878],\n",
       "       [-0.254279  , -0.34693878],\n",
       "       [-0.28828728, -0.3877551 ]])"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MinMaxScaler()\n",
    "for k, v in param.items():\n",
    "    setattr(model, k, v)\n",
    "model.fit_transform(DATA[['atemp', 'temp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param['feature_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_range': (-1, 1)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(-1, 1))"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = dict(feature_range=(-1,1))\n",
    "print(param)\n",
    "model = MinMaxScaler()\n",
    "\n",
    "for k, v in param.items():\n",
    "    setattr(model, k, v)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-639-0acfb4d5c999>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'atemp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'temp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0mdata_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_max\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdata_min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         self.scale_ = ((feature_range[1] - feature_range[0]) /\n\u001b[0m\u001b[0;32m    378\u001b[0m                        _handle_zeros_in_scale(data_range))\n\u001b[0;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdata_min\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "print(MinMaxScaler())\n",
    "cclf = change_params(MinMaxScaler(), con)\n",
    "cclf.fit_transform(DATA[['atemp', 'temp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'req_01': {'condition': '', 'field_name': 'atemp', 'pfunc_pk': 1},\n",
      " 'req_02': {'condition': {'feature_range': (-1, 1)},\n",
      "            'field_name': 'humidity',\n",
      "            'pfunc_pk': 2},\n",
      " 'req_03': {'field_name': 'temp', 'pfunc_pk': 1},\n",
      " 'req_04': {'condition': {'categories': 'auto', 'sparse': False},\n",
      "            'field_name': 'weather',\n",
      "            'pfunc_pk': 3}}\n"
     ]
    }
   ],
   "source": [
    "pprint(request) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'LIBRARY_FUNCTION_NAME': 'StandardScaler',\n",
      "       'LIBRARY_NAME': 'sklearn',\n",
      "       'LIBRARY_OBJECT_NAME': 'preprocessing',\n",
      "       'pk': 1},\n",
      " '2': {'LIBRARY_FUNCTION_NAME': 'MinMaxScaler',\n",
      "       'LIBRARY_NAME': 'sklearn',\n",
      "       'LIBRARY_OBJECT_NAME': 'preprocessing',\n",
      "       'pk': 2},\n",
      " '3': {'LIBRARY_FUNCTION_NAME': 'OneHotEncoder',\n",
      "       'LIBRARY_NAME': 'sklearn',\n",
      "       'LIBRARY_OBJECT_NAME': 'preprocessing',\n",
      "       'pk': 3}}\n"
     ]
    }
   ],
   "source": [
    "pprint(pfunc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\daumsoft\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh = OneHotEncoder()\n",
    "oh_trf = oh.fit_transform(DATA['weather'].values.reshape(-1,1)).toarray()\n",
    "oh_trf[5631:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = OneHotEncoder() \n",
    "mm = MinMaxScaler()\n",
    "#oh_trf = oh.fit_transform(DATA['temp'].values.reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[1. 0. 0. 0.]',\n",
       " '[1. 0. 0. 0.]',\n",
       " '[1. 0. 0. 0.]',\n",
       " '[1. 0. 0. 0.]',\n",
       " '[1. 0. 0. 0.]']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_transformer(field, transformer):\n",
    "    NUM = 5\n",
    "    try:\n",
    "        transformer.fit(field) #필드가 두 개 이상일 때 \n",
    "        changed_field = transformer.transform(field)\n",
    "    except:\n",
    "        transformer.fit(field.values.reshape(-1,1)) #필드가 하나일 때 \n",
    "        changed_field = transformer.transform(field.values.reshape(-1,1))\n",
    "\n",
    "    print(changed_field[:NUM].shape)\n",
    "    return changed_field[:NUM]\n",
    "\n",
    "\n",
    "r_ = test_transformer(DATA['weather'], oh)\n",
    "print(type(r_))\n",
    "if r_.shape == (5,1): #numerical 전처리의 경우에 해당 \n",
    "    changed_field = list(map(lambda x: \"%.4f\" %x, list(flatten(r_[:5]))))\n",
    "else: #그 외 (예, 원핫인코딩)에 해당 \n",
    "    #r_ = r_.toarray()\n",
    "    r_ = r_.toarray() if not isinstance(r_, np.ndarray) else r_ #sp.sparse.csr_matrix\n",
    "    print(type(r_))\n",
    "    changed_field = list(map(lambda x:str(x), r_[:5]))\n",
    "    \n",
    "changed_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(re_, np.ndarray), isinstance(r_, sp.sparse.csr_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = r_.A\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'three'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_ = np.array([1,2,3])\n",
    "\n",
    "#print('one') if isinstance(re_, np.ndarray) else None\n",
    "\n",
    "'three' if isinstance(re_, np.ndarray) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atemp 필드의 StandardScaler 전처리를 수행....\n",
      "humidity 필드의 MinMaxScaler 전처리를 수행....\n",
      "temp 필드의 StandardScaler 전처리를 수행....\n",
      "weather 필드의 OneHotEncoder 전처리를 수행....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'atemp': '-1.0927',\n",
       "  'humidity': '0.8100',\n",
       "  'temp': '-1.3337',\n",
       "  'weather': '  (0, 0)\\t1.0'},\n",
       " {'atemp': '-1.1824',\n",
       "  'humidity': '0.8000',\n",
       "  'temp': '-1.4389',\n",
       "  'weather': '  (0, 0)\\t1.0'},\n",
       " {'atemp': '-1.1824',\n",
       "  'humidity': '0.8000',\n",
       "  'temp': '-1.4389',\n",
       "  'weather': '  (0, 0)\\t1.0'},\n",
       " {'atemp': '-1.0927',\n",
       "  'humidity': '0.7500',\n",
       "  'temp': '-1.3337',\n",
       "  'weather': '  (0, 0)\\t1.0'},\n",
       " {'atemp': '-1.0927',\n",
       "  'humidity': '0.7500',\n",
       "  'temp': '-1.3337',\n",
       "  'weather': '  (0, 0)\\t1.0'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_transformer(request):\n",
    "    DATA = bike.copy() #원본데이터 \n",
    "    DF = pd.DataFrame()\n",
    "    NUM = 5 #전치리된 결과를 보여줄 row 갯수 \n",
    "\n",
    "    for user_request in request:\n",
    "        get_request_dict = request[user_request] #전처리 테스트 요청 (전처리번호, 필드이름, 조건(있으면)) (딕셔너리 형태)\n",
    "        get_pfunc = pfunc[str(get_request_dict['pfunc_pk'])] #db에서 가져온 전처리 정보 (딕셔너리 형태 )\n",
    "        get_field = DATA[get_request_dict['field_name']].astype(float) #전처리를 수행할 필드\n",
    "        transformer = get_transformer(get_pfunc) #전처리를 수행할 변환기 가져오기 \n",
    "        try:\n",
    "            get_condition = get_request_dict['condition'] #조건 (있으면)\n",
    "            transformer = change_params(transformer, get_condition) #조건 (있으면 변환기 파라미터 수정해서 가져오기)\n",
    "        except:\n",
    "            pass\n",
    "        print('{} 필드의 {} 전처리를 수행....'.format(get_request_dict['field_name'], get_pfunc['LIBRARY_FUNCTION_NAME']))\n",
    "        try:\n",
    "            transformer.fit(get_field)\n",
    "            changed_field = transformer.transform(get_field)\n",
    "        except:\n",
    "            transformer.fit(get_field.values.reshape(-1,1))\n",
    "            changed_field = transformer.transform(get_field.values.reshape(-1,1))\n",
    "        if changed_field[:NUM].shape == (5,1):\n",
    "            changed_field = list(map(lambda x:format(x, '.4f'), list(flatten(changed_field[:NUM]))))\n",
    "        else:\n",
    "            changed_field = list(map(lambda x:str(x), changed_field[:NUM]))\n",
    "\n",
    "        to_df = pd.DataFrame(changed_field, columns=[get_request_dict['field_name']])\n",
    "        DF = pd.concat([DF, to_df], axis=1)\n",
    "    result = DF.to_dict(orient='records') \n",
    "    return result\n",
    "\n",
    "get_result = fit_transformer(request=request)\n",
    "get_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atemp 필드의 StandardScaler 전처리를 수행....\n",
      "['-1.0927', '-1.1824', '-1.1824', '-1.0927', '-1.0927']\n",
      "humidity 필드의 MinMaxScaler 전처리를 수행....\n",
      "['0.6200', '0.6000', '0.6000', '0.5000', '0.5000']\n",
      "temp 필드의 StandardScaler 전처리를 수행....\n",
      "['-1.3337', '-1.4389', '-1.4389', '-1.3337', '-1.3337']\n",
      "weather 필드의 OneHotEncoder 전처리를 수행....\n",
      "['[1. 0. 0. 0.]', '[1. 0. 0. 0.]', '[1. 0. 0. 0.]', '[1. 0. 0. 0.]', '[1. 0. 0. 0.]']\n",
      "\n",
      " ==============done==============\n",
      "\n",
      "response!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'atemp': '-1.0927',\n",
       "  'humidity': '0.6200',\n",
       "  'temp': '-1.3337',\n",
       "  'weather': '[1. 0. 0. 0.]'},\n",
       " {'atemp': '-1.1824',\n",
       "  'humidity': '0.6000',\n",
       "  'temp': '-1.4389',\n",
       "  'weather': '[1. 0. 0. 0.]'},\n",
       " {'atemp': '-1.1824',\n",
       "  'humidity': '0.6000',\n",
       "  'temp': '-1.4389',\n",
       "  'weather': '[1. 0. 0. 0.]'},\n",
       " {'atemp': '-1.0927',\n",
       "  'humidity': '0.5000',\n",
       "  'temp': '-1.3337',\n",
       "  'weather': '[1. 0. 0. 0.]'},\n",
       " {'atemp': '-1.0927',\n",
       "  'humidity': '0.5000',\n",
       "  'temp': '-1.3337',\n",
       "  'weather': '[1. 0. 0. 0.]'}]"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "DATA = bike.copy() #원본데이터 \n",
    "DF = pd.DataFrame()\n",
    "#result = defaultdict(list)\n",
    "NUM = 5 #전치리된 결과를 보여줄 row 갯수 \n",
    "\n",
    "for user_request in request:\n",
    "    get_request_dict = request[user_request] #전처리 테스트 요청 (전처리번호, 필드이름, 조건(있으면)) (딕셔너리 형태)\n",
    "    #{'pfunc_pk': 1, 'field_name': 'atemp', 'condition': ''}\n",
    "    get_pfunc = pfunc[str(get_request_dict['pfunc_pk'])] #db에서 가져온 전처리 정보 (딕셔너리 형태 )\n",
    "    #{'pk': 1, 'LIBRARY_NAME': 'sklearn', 'LIBRARY_OBJECT_NAME': 'preprocessing', 'LIBRARY_FUNCTION_NAME': 'StandardScaler'}\n",
    "    get_field = DATA[get_request_dict['field_name']].astype(float) #전처리를 수행할 필드\n",
    "    \n",
    "    transformer = get_transformer(get_pfunc) #전처리를 수행할 변환기 가져오기 \n",
    "    try:\n",
    "        get_condition = get_request_dict['condition'] #조건 (있으면)\n",
    "        transformer = change_params(transformer, get_condition) #조건 (있으면 변환기 파라미터 수정해서 가져오기)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print('{} 필드의 {} 전처리를 수행....'.format(get_request_dict['field_name'], get_pfunc['LIBRARY_FUNCTION_NAME']))\n",
    "\n",
    "    try:\n",
    "        transformer.fit(get_field)\n",
    "        changed_field = transformer.transform(get_field)\n",
    "    except:\n",
    "        transformer.fit(get_field.values.reshape(-1,1))\n",
    "        changed_field = transformer.transform(get_field.values.reshape(-1,1))\n",
    "        \n",
    "    \n",
    "    if changed_field[:NUM].shape == (5,1):\n",
    "        changed_field = list(map(lambda x:format(x, '.4f'), list(flatten(changed_field[:NUM]))))\n",
    "    else:\n",
    "        changed_field = list(map(lambda x:str(x), changed_field[:NUM]))\n",
    "        \n",
    "    print(changed_field)\n",
    "    to_df = pd.DataFrame(changed_field, columns=[get_request_dict['field_name']])\n",
    "    DF = pd.concat([DF, to_df], axis=1)\n",
    "    #for k, v in enumerate(changed_field):\n",
    "    #    result[k].append(v)\n",
    "print('\\n ==============done==============\\n')\n",
    "\n",
    "    \n",
    "print('response!')\n",
    "result = DF.to_dict(orient='records') \n",
    "result\n",
    "#result = dict(result)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'atemp': '-1.0927',\n",
      "     'humidity': '0.6200',\n",
      "     'temp': '-1.3337',\n",
      "     'weather': '[1. 0. 0. 0.]'},\n",
      " 1: {'atemp': '-1.1824',\n",
      "     'humidity': '0.6000',\n",
      "     'temp': '-1.4389',\n",
      "     'weather': '[1. 0. 0. 0.]'},\n",
      " 2: {'atemp': '-1.1824',\n",
      "     'humidity': '0.6000',\n",
      "     'temp': '-1.4389',\n",
      "     'weather': '[1. 0. 0. 0.]'},\n",
      " 3: {'atemp': '-1.0927',\n",
      "     'humidity': '0.5000',\n",
      "     'temp': '-1.3337',\n",
      "     'weather': '[1. 0. 0. 0.]'},\n",
      " 4: {'atemp': '-1.0927',\n",
      "     'humidity': '0.5000',\n",
      "     'temp': '-1.3337',\n",
      "     'weather': '[1. 0. 0. 0.]'}}\n"
     ]
    }
   ],
   "source": [
    "fresult =  dict(zip(range(len(result)), result))\n",
    "pprint(fresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(categories='auto')\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "encoder.fit(DATA['weather'].values.reshape(-1,1))\n",
    "changed_field = encoder.transform(DATA['weather'].values.reshape(-1,1))\n",
    "changed_field[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1. 0. 0. 0.]'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = list(map(lambda x:str(x), changed_field[:5]))\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.8165', '-1.2247', '-1.2247', '0.8165', '0.8165']"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = list(map(lambda x:format(x, '.4f'), list(flatten(changed_field))))\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atemp': 0.816496580927727, 'humidity': 1.0, 'temp': 0.8164965809277243}\n",
      "{'atemp': -1.224744871391588, 'humidity': 0.6666666666666643, 'temp': -1.2247448713915907}\n",
      "{'atemp': -1.224744871391588, 'humidity': 0.6666666666666643, 'temp': -1.2247448713915907}\n",
      "{'atemp': 0.816496580927727, 'humidity': -1.0, 'temp': 0.8164965809277243}\n",
      "{'atemp': 0.816496580927727, 'humidity': -1.0, 'temp': 0.8164965809277243}\n"
     ]
    }
   ],
   "source": [
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.880</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.880</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.425</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    atemp  humidity\n",
       "0  14.395        81\n",
       "1  13.635        80\n",
       "2  13.635        80\n",
       "3  14.395        75\n",
       "4  14.395        75\n",
       "5  12.880        75\n",
       "6  13.635        80\n",
       "7  12.880        86\n",
       "8  14.395        75\n",
       "9  17.425        76"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_field = DATA[['atemp', 'humidity']][:10]  #atemp, humidity, [['atemp', 'humidity']]\n",
    "get_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.33333333,  0.09090909],\n",
       "       [-0.66776678, -0.09090909],\n",
       "       [-0.66776678, -0.09090909],\n",
       "       [-0.33333333, -1.        ],\n",
       "       [-0.33333333, -1.        ],\n",
       "       [-1.        , -1.        ],\n",
       "       [-0.66776678, -0.09090909],\n",
       "       [-1.        ,  1.        ],\n",
       "       [-0.33333333, -1.        ],\n",
       "       [ 1.        , -0.81818182]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_field=get_field.astype(float)\n",
    "try:\n",
    "    print('here')\n",
    "    transformer.fit(get_field)\n",
    "    print('here')\n",
    "    changed_f1 = transformer.fit_transform(get_field)\n",
    "except:\n",
    "    print('here2')\n",
    "    transformer.fit(get_field.values.reshape(-1,1))\n",
    "    print('here2')\n",
    "    changed_f1 = transformer.fit_transform(get_field.values.reshape(-1,1))\n",
    "changed_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer(params):\n",
    "    module_ = __import__(params['LIBRARY_NAME'])\n",
    "    class_ = getattr(module_, params['LIBRARY_OBJECT_NAME'])\n",
    "    transformer_ = getattr(class_, params['LIBRARY_FUNCTION_NAME'])\n",
    "    transformer  = transformer_()\n",
    "    return transformer   \n",
    "\n",
    "def change_params(model, param):\n",
    "    try:\n",
    "        for k, v in param.items():\n",
    "            setattr(model, k, v)\n",
    "        return model\n",
    "\n",
    "    except:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize='True', random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = Ridge()\n",
    "clf_ = RandomForestClassifier()\n",
    "user_param = '{\"normalize\":\"True\"}'\n",
    "print(type(user_param))\n",
    "user_param = json.loads(user_param)\n",
    "print(type(user_param))\n",
    "clf2 = change_params(clf, user_param)\n",
    "clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30506768],\n",
       "       [0.28806354],\n",
       "       [0.28806354],\n",
       "       [0.30506768],\n",
       "       [0.30506768]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale_fit = mm_scaler.fit(DATA[COLUMN].values.reshape(-1,1))\n",
    "#x_scaled = scale_fit.transform(DATA[COLUMN].values.reshape(-1,1))\n",
    "x_scaled = mm_scaler.fit_transform(DATA[COLUMN].values.reshape(-1,1))\n",
    "print(scale_fit.n_samples_seen_)\n",
    "x_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.39</td>\n",
       "      <td>81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.63</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.63</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.39</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.39</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp  atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.39   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.63   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.63   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.39   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.39   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81       0.00       3          13     16  \n",
       "1        80       0.00       8          32     40  \n",
       "2        80       0.00       5          27     32  \n",
       "3        75       0.00       3          10     13  \n",
       "4        75       0.00       0           1      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>2012-12-19 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.70</td>\n",
       "      <td>50</td>\n",
       "      <td>26.00</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>2012-12-19 20:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.43</td>\n",
       "      <td>57</td>\n",
       "      <td>15.00</td>\n",
       "      <td>10</td>\n",
       "      <td>231</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>2012-12-19 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>15.91</td>\n",
       "      <td>61</td>\n",
       "      <td>15.00</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>2012-12-19 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>17.43</td>\n",
       "      <td>61</td>\n",
       "      <td>6.00</td>\n",
       "      <td>12</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>2012-12-19 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>16.66</td>\n",
       "      <td>66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  season  holiday  workingday  weather  temp  atemp  \\\n",
       "10881  2012-12-19 19:00:00       4        0           1        1 15.58  19.70   \n",
       "10882  2012-12-19 20:00:00       4        0           1        1 14.76  17.43   \n",
       "10883  2012-12-19 21:00:00       4        0           1        1 13.94  15.91   \n",
       "10884  2012-12-19 22:00:00       4        0           1        1 13.94  17.43   \n",
       "10885  2012-12-19 23:00:00       4        0           1        1 13.12  16.66   \n",
       "\n",
       "       humidity  windspeed  casual  registered  count  \n",
       "10881        50      26.00       7         329    336  \n",
       "10882        57      15.00      10         231    241  \n",
       "10883        61      15.00       4         164    168  \n",
       "10884        61       6.00      12         117    129  \n",
       "10885        66       9.00       4          84     88  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp  atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84   0.31   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02   0.29   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02   0.29   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84   0.31   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84   0.31   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81       0.00       3          13     16  \n",
       "1        80       0.00       8          32     40  \n",
       "2        80       0.00       5          27     32  \n",
       "3        75       0.00       3          10     13  \n",
       "4        75       0.00       0           1      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA[COLUMN] = x_scaled\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30506768],\n",
       "       [0.28806354],\n",
       "       [0.28806354],\n",
       "       ...,\n",
       "       [0.33896409],\n",
       "       [0.3728605 ],\n",
       "       [0.35585636]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30506768],\n",
       "       [0.28806354],\n",
       "       [0.28806354],\n",
       "       [0.30506768],\n",
       "       [0.30506768]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_02 = scale_fit.transform(unseen_data)\n",
    "scaled_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_estimator(estimator, estimator_name):\n",
    "    file_path = os.path.join(current_dir, estimator_name)\n",
    "    joblib.dump(estimator, file_path)\n",
    "    return file_path, estimator_name\n",
    "\n",
    "def load_estimator(model_name):\n",
    "    file_path = os.path.join(current_dir, model_name)\n",
    "    clf = joblib.load(file_path)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Daumsoft\\\\Desktop\\\\mm_scaler.pickle'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, fname = save_estimator(mm_scaler, 'mm_scaler.pickle')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_scaler = load_estimator('mm_scaler.pickle')\n",
    "load_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_scaler.n_samples_seen_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.395],\n",
       "       [13.635],\n",
       "       [13.635],\n",
       "       [14.395],\n",
       "       [14.395]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30506768],\n",
       "       [0.28806354],\n",
       "       [0.28806354],\n",
       "       [0.30506768],\n",
       "       [0.30506768]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_scaled = load_scaler.transform(unseen_data)\n",
    "unseen_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_scaler.n_samples_seen_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
